# Ollama Gemma 3 270M Production Container
FROM ollama/ollama:latest

LABEL maintainer="GrantSeeker AI Platform" \
      description="Ollama container with Gemma 3 270M-IT for production AI inference" \
      version="1.0.0-ollama-gemma"

# Set working directory
WORKDIR /app

# Install curl for health checks
RUN apt-get update && apt-get install -y curl && rm -rf /var/lib/apt/lists/*

# Copy startup script
COPY ollama-gemma-startup.sh /app/startup.sh
RUN chmod +x /app/startup.sh

# Create ollama user data directory with proper permissions
RUN mkdir -p /root/.ollama && chmod 755 /root/.ollama

# Expose Ollama port
EXPOSE 11434

# Health check - more generous timing for Gemma model
HEALTHCHECK --interval=30s --timeout=15s --start-period=300s --retries=5 \
    CMD curl -f http://localhost:11434/api/tags || exit 1

# Set environment variables for optimization
ENV OLLAMA_HOST=0.0.0.0:11434
ENV OLLAMA_KEEP_ALIVE=24h
ENV OLLAMA_MAX_LOADED_MODELS=1

# Start Ollama with Gemma 3 270M
CMD ["/app/startup.sh"]